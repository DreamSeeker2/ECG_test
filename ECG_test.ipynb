{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG_test.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1mFFBbDtyIzl3wMsp5IHnsQV0yWH--Knl",
      "authorship_tag": "ABX9TyMGhXonR1qZtWAa5hYcIXjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cauc1ronman/Xin-Dong/blob/master/ECG_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLrDECvuc4qg"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO3UKoHM80Wf"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM7AAYl7c7ra"
      },
      "source": [
        "#! /usr/bin/enc python\n",
        "# -*- coding: utf-8 -*-\n",
        "# author: Jarvis Dong\n",
        "# email: cauc1ronman@outlook.com\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Fine-tuneable\n",
        "# def replace_head(model, num_classes):\n",
        "#     model[-1][-1] = nn.Linear(512, num_classes)\n",
        "#     apply_init(model[1], nn.init.kaiming_normal_)\n",
        "\n",
        "# conv1xk (3x3,stride=1)\n",
        "def conv1xk(in_channels,out_channels,kernel_size=3,stride=1):\n",
        "    padding = kernel_size//2\n",
        "    return nn.Conv1d(in_channels,out_channels,kernel_size=kernel_size,\n",
        "                        stride=stride,padding=padding,bias=False)\n",
        "\n",
        "# initialization\n",
        "def init_cnn_1d(m):\n",
        "    if getattr(m, 'bias', None) is not None:\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv1d,nn.Linear)):\n",
        "        nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_cnn_1d(l)\n",
        "\n",
        "# def  splitter(m):\n",
        "#     return L(m[0][:6], m[0][6:], m[1]).map(params)\n",
        "\n",
        "# Residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv1xk(in_channels, out_channels, kernel_size, stride)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv1xk(out_channels, out_channels, kernel_size)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(residual)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# Resnet1D\n",
        "class ResNet_ecg(nn.Sequential):\n",
        "    def __init__(self,block,layers,in_channels=64,num_classes=10,kernel_size=3,stride=2,dropout=0.2):\n",
        "        \"\"\"\n",
        "\n",
        "        :param block:\n",
        "        :param layers:\n",
        "        :param in_channels:\n",
        "        :param num_classes:\n",
        "        :param kernel_size:\n",
        "        :param stride:\n",
        "        :param dropout:\n",
        "        \"\"\"\n",
        "        in_block = [] # input_block\n",
        "        residual_block = [] # residual blocks\n",
        "        header_block = [] # linear head\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.block = block\n",
        "\n",
        "        in_kernel_size = kernel_size*2 + 1\n",
        "\n",
        "        in_block.append(conv1xk(1, in_channels, in_kernel_size, stride))\n",
        "        in_block.append(nn.BatchNorm1d(in_channels))\n",
        "        in_block.append(nn.ReLU(inplace=True))\n",
        "        in_block.append(nn.MaxPool1d(kernel_size, stride, kernel_size//3))\n",
        "\n",
        "        residual_block = self.make_blocks(layers, in_channels, kernel_size, stride)\n",
        "\n",
        "        header_block.append(nn.AdaptiveAvgPool1d(1))\n",
        "        header_block.append(nn.Flatten())\n",
        "        # header_block.append(nn.Dropout(dropout))\n",
        "        # header_block.append(nn.Linear(in_channels*2**(len(layers)-1), num_classes))\n",
        "        header_block.append(nn.Linear(in_channels*2**(len(layers)-1), 128))\n",
        "        header_block.append(nn.BatchNorm1d(128))\n",
        "        header_block.append(nn.ReLU(inplace=True))\n",
        "        # header_block.append(nn.Dropout(dropout))\n",
        "        # header_block.append(nn.Linear(2048,512))\n",
        "        # header_block.append(nn.BatchNorm1d(512))\n",
        "        # header_block.append(nn.ReLU(inplace=True))\n",
        "        # header_block.append(nn.Linear(512,512))\n",
        "        # header_block.append(nn.ReLU(inplace=True))\n",
        "        header_block.append(nn.Linear(128,num_classes))\n",
        "\n",
        "        super().__init__(nn.Sequential(*in_block,*residual_block),nn.Sequential(*header_block))\n",
        "        init_cnn_1d(self)\n",
        "\n",
        "    def make_blocks(self, layers, in_channels, kernel_size, stride):\n",
        "        return [self.make_layer(self.block, in_channels*2**i, l, kernel_size, stride) for i, l in enumerate(layers)]\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, kernel_size=3, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv1xk (self.in_channels, out_channels, kernel_size=kernel_size, stride=stride),\n",
        "                nn.BatchNorm1d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, kernel_size, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels, kernel_size))\n",
        "        return nn.Sequential(*layers)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTf1gCpO9zT-"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1C_ilIz90_3"
      },
      "source": [
        "#! /usr/bin/enc python\n",
        "# -*- coding: utf-8 -*-\n",
        "# author: Jarvis Dong\n",
        "# email: cauc1ronman@outlook.com\n",
        "\n",
        "from sklearn.metrics import precision_score \n",
        "from sklearn.metrics import recall_score \n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.metrics import accuracy_score \n",
        "import inspect \n",
        "\n",
        "from torch.optim.lr_scheduler import _LRScheduler \n",
        "\n",
        "def calculate_metric(metric_fn, true_y, pred_y):\n",
        "  # multi class problems need to have averaging method\n",
        "  if \"average\" in inspect.getfullargspec(metric_fn).args:\n",
        "    return metric_fn(true_y, pred_y, average=\"macro\")\n",
        "  else:\n",
        "    return metric_fn(true_y, pred_y)\n",
        "    \n",
        "def print_scores(p, r, f1, a, batch_size):\n",
        "  # just an utility printing function\n",
        "  for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
        "    print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")\n",
        "\n",
        "class WarmUpLR(_LRScheduler):\n",
        "  \"\"\"warmup_training learning rate scheduler\n",
        "  Args:\n",
        "      optimizer: optimzier(e.g. SGD)\n",
        "      total_iters: totoal_iters of warmup phase\n",
        "  \"\"\"\n",
        "  def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
        "    self.total_iters = total_iters\n",
        "    super().__init__(optimizer, last_epoch)\n",
        "\n",
        "  def get_lr(self):\n",
        "    \"\"\"we will use the first m batches, and set the learning\n",
        "    rate to base_lr * m / total_iters\n",
        "    \"\"\"\n",
        "    return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwmthQCg98-l",
        "outputId": "dc55e946-2ee0-4ca6-c7f2-4df5a5ed1fbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#! /usr/bin/enc python\n",
        "# -*- coding: utf-8 -*-\n",
        "# author: Jarvis Dong\n",
        "# email: cauc1ronman@outlook.com\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "# from Model.ResNet18_34.Model import *\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "import time\n",
        "\n",
        "import torch \n",
        "# 清除GPU内存 \n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# sys.path.append(\"Model\") # 改用torchvision的改写版的resnet1d \n",
        "# torch.cuda.empty_cache() # clean the cache of gpu\n",
        "\n",
        "device_str = \"cuda\"\n",
        "device = torch.device(device_str if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"current device\",device)\n",
        "\n",
        "RES1D18 = {\n",
        "    \"block\":ResidualBlock,\n",
        "    \"layers\":[2,2,2,2],\n",
        "    \"in_channels\":128,\n",
        "    \"kernel_size\":15,\n",
        "    \"stride\":4,\n",
        "    \"num_classes\":5 # order 0 to 4\n",
        "}\n",
        "\n",
        "RES1D34 = {\n",
        "    \"block\": ResidualBlock,\n",
        "    \"layers\": [3, 4, 6, 3],\n",
        "    \"in_channels\": 64,\n",
        "    \"kernel_size\": 15,\n",
        "    \"stride\": 4,\n",
        "    \"num_classes\": 5 #order 0 to 4\n",
        "}\n",
        "\n",
        "# # signal params \n",
        "# Fs = 2048\n",
        "# times = np.arange(0,1,1/Fs)\n",
        "\n",
        "# batch_size = 32 \n",
        "# batch_size = 64\n",
        "batch_size = 64 \n",
        "num_workers = 0 \n",
        "\n",
        "num_epochs = 500\n",
        "step = 0 \n",
        "\n",
        "config = RES1D18 \n",
        "# config = RES1D34\n",
        "config['num_classes']= 5\n",
        "\n",
        "save_every_epoch = 10\n",
        "test_every_epoch = 1  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current device cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQKuME8S-S2G"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OceRwKmIwRN5"
      },
      "source": [
        "# spoto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OZU83l1R4fp",
        "outputId": "44c85843-bbf4-448e-d1a0-6cbbbf843b67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Generated by the protocol buffer compiler.  DO NOT EDIT!\n",
        "# source: tensor.proto\n",
        "\n",
        "from google.protobuf import descriptor as _descriptor\n",
        "from google.protobuf import message as _message\n",
        "from google.protobuf import reflection as _reflection\n",
        "from google.protobuf import symbol_database as _symbol_database\n",
        "# @@protoc_insertion_point(imports)\n",
        "\n",
        "_sym_db = _symbol_database.Default()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DESCRIPTOR = _descriptor.FileDescriptor(\n",
        "  name='tensor.proto',\n",
        "  package='',\n",
        "  syntax='proto3',\n",
        "  serialized_options=None,\n",
        "  create_key=_descriptor._internal_create_key,\n",
        "  serialized_pb=b'\\n\\x0ctensor.proto\\\",\\n\\x0cTensorProtos\\x12\\x1c\\n\\x06protos\\x18\\x01 \\x03(\\x0b\\x32\\x0c.TensorProto\\\"\\xe0\\x02\\n\\x0bTensorProto\\x12\\x0c\\n\\x04\\x64ims\\x18\\x01 \\x03(\\x03\\x12(\\n\\tdata_type\\x18\\x02 \\x01(\\x0e\\x32\\x15.TensorProto.DataType\\x12\\x12\\n\\nfloat_data\\x18\\x03 \\x03(\\x02\\x12\\x12\\n\\nint32_data\\x18\\x04 \\x03(\\x05\\x12\\x11\\n\\tbyte_data\\x18\\x05 \\x01(\\x0c\\x12\\x13\\n\\x0bstring_data\\x18\\x06 \\x03(\\x0c\\x12\\x13\\n\\x0b\\x64ouble_data\\x18\\x07 \\x03(\\x01\\x12\\x12\\n\\nint64_data\\x18\\x08 \\x03(\\x03\\\"\\x9f\\x01\\n\\x08\\x44\\x61taType\\x12\\r\\n\\tUNDEFINED\\x10\\x00\\x12\\t\\n\\x05\\x46LOAT\\x10\\x01\\x12\\t\\n\\x05INT32\\x10\\x02\\x12\\x08\\n\\x04\\x42YTE\\x10\\x03\\x12\\n\\n\\x06STRING\\x10\\x04\\x12\\x08\\n\\x04\\x42OOL\\x10\\x05\\x12\\t\\n\\x05UINT8\\x10\\x06\\x12\\x08\\n\\x04INT8\\x10\\x07\\x12\\n\\n\\x06UINT16\\x10\\x08\\x12\\t\\n\\x05INT16\\x10\\t\\x12\\t\\n\\x05INT64\\x10\\n\\x12\\x0b\\n\\x07\\x46LOAT16\\x10\\x0c\\x12\\n\\n\\x06\\x44OUBLE\\x10\\rb\\x06proto3'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "_TENSORPROTO_DATATYPE = _descriptor.EnumDescriptor(\n",
        "  name='DataType',\n",
        "  full_name='TensorProto.DataType',\n",
        "  filename=None,\n",
        "  file=DESCRIPTOR,\n",
        "  create_key=_descriptor._internal_create_key,\n",
        "  values=[\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='UNDEFINED', index=0, number=0,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='FLOAT', index=1, number=1,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='INT32', index=2, number=2,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='BYTE', index=3, number=3,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='STRING', index=4, number=4,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='BOOL', index=5, number=5,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='UINT8', index=6, number=6,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='INT8', index=7, number=7,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='UINT16', index=8, number=8,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='INT16', index=9, number=9,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='INT64', index=10, number=10,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='FLOAT16', index=11, number=12,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.EnumValueDescriptor(\n",
        "      name='DOUBLE', index=12, number=13,\n",
        "      serialized_options=None,\n",
        "      type=None,\n",
        "      create_key=_descriptor._internal_create_key),\n",
        "  ],\n",
        "  containing_type=None,\n",
        "  serialized_options=None,\n",
        "  serialized_start=256,\n",
        "  serialized_end=415,\n",
        ")\n",
        "_sym_db.RegisterEnumDescriptor(_TENSORPROTO_DATATYPE)\n",
        "\n",
        "\n",
        "_TENSORPROTOS = _descriptor.Descriptor(\n",
        "  name='TensorProtos',\n",
        "  full_name='TensorProtos',\n",
        "  filename=None,\n",
        "  file=DESCRIPTOR,\n",
        "  containing_type=None,\n",
        "  create_key=_descriptor._internal_create_key,\n",
        "  fields=[\n",
        "    _descriptor.FieldDescriptor(\n",
        "      name='protos', full_name='TensorProtos.protos', index=0,\n",
        "      number=1, type=11, cpp_type=10, label=3,\n",
        "      has_default_value=False, default_value=[],\n",
        "      message_type=None, enum_type=None, containing_type=None,\n",
        "      is_extension=False, extension_scope=None,\n",
        "      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
        "  ],\n",
        "  extensions=[\n",
        "  ],\n",
        "  nested_types=[],\n",
        "  enum_types=[\n",
        "  ],\n",
        "  serialized_options=None,\n",
        "  is_extendable=False,\n",
        "  syntax='proto3',\n",
        "  extension_ranges=[],\n",
        "  oneofs=[\n",
        "  ],\n",
        "  serialized_start=16,\n",
        "  serialized_end=60,\n",
        ")\n",
        "\n",
        "\n",
        "_TENSORPROTO = _descriptor.Descriptor(\n",
        "  name='TensorProto',\n",
        "  full_name='TensorProto',\n",
        "  filename=None,\n",
        "  file=DESCRIPTOR,\n",
        "  containing_type=None,\n",
        "  create_key=_descriptor._internal_create_key,\n",
        "  fields=[\n",
        "    _descriptor.FieldDescriptor(\n",
        "      name='dims', full_name='TensorProto.dims', index=0,\n",
        "      number=1, type=3, cpp_type=2, label=3,\n",
        "      has_default_value=False, default_value=[],\n",
        "      message_type=None, enum_type=None, containing_type=None,\n",
        "      is_extension=False, extension_scope=None,\n",
        "      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.FieldDescriptor(\n",
        "      name='data_type', full_name='TensorProto.data_type', index=1,\n",
        "      number=2, type=14, cpp_type=8, label=1,\n",
        "      has_default_value=False, default_value=0,\n",
        "      message_type=None, enum_type=None, containing_type=None,\n",
        "      is_extension=False, extension_scope=None,\n",
        "      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.FieldDescriptor(\n",
        "      name='float_data', full_name='TensorProto.float_data', index=2,\n",
        "      number=3, type=2, cpp_type=6, label=3,\n",
        "      has_default_value=False, default_value=[],\n",
        "      message_type=None, enum_type=None, containing_type=None,\n",
        "      is_extension=False, extension_scope=None,\n",
        "      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.FieldDescriptor(\n",
        "      name='int32_data', full_name='TensorProto.int32_data', index=3,\n",
        "      number=4, type=5, cpp_type=1, label=3,\n",
        "      has_default_value=False, default_value=[],\n",
        "      message_type=None, enum_type=None, containing_type=None,\n",
        "      is_extension=False, extension_scope=None,\n",
        "      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.FieldDescriptor(\n",
        "      name='byte_data', full_name='TensorProto.byte_data', index=4,\n",
        "      number=5, type=12, cpp_type=9, label=1,\n",
        "      has_default_value=False, default_value=b\"\",\n",
        "      message_type=None, enum_type=None, containing_type=None,\n",
        "      is_extension=False, extension_scope=None,\n",
        "      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.FieldDescriptor(\n",
        "      name='string_data', full_name='TensorProto.string_data', index=5,\n",
        "      number=6, type=12, cpp_type=9, label=3,\n",
        "      has_default_value=False, default_value=[],\n",
        "      message_type=None, enum_type=None, containing_type=None,\n",
        "      is_extension=False, extension_scope=None,\n",
        "      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.FieldDescriptor(\n",
        "      name='double_data', full_name='TensorProto.double_data', index=6,\n",
        "      number=7, type=1, cpp_type=5, label=3,\n",
        "      has_default_value=False, default_value=[],\n",
        "      message_type=None, enum_type=None, containing_type=None,\n",
        "      is_extension=False, extension_scope=None,\n",
        "      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
        "    _descriptor.FieldDescriptor(\n",
        "      name='int64_data', full_name='TensorProto.int64_data', index=7,\n",
        "      number=8, type=3, cpp_type=2, label=3,\n",
        "      has_default_value=False, default_value=[],\n",
        "      message_type=None, enum_type=None, containing_type=None,\n",
        "      is_extension=False, extension_scope=None,\n",
        "      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),\n",
        "  ],\n",
        "  extensions=[\n",
        "  ],\n",
        "  nested_types=[],\n",
        "  enum_types=[\n",
        "    _TENSORPROTO_DATATYPE,\n",
        "  ],\n",
        "  serialized_options=None,\n",
        "  is_extendable=False,\n",
        "  syntax='proto3',\n",
        "  extension_ranges=[],\n",
        "  oneofs=[\n",
        "  ],\n",
        "  serialized_start=63,\n",
        "  serialized_end=415,\n",
        ")\n",
        "\n",
        "_TENSORPROTOS.fields_by_name['protos'].message_type = _TENSORPROTO\n",
        "_TENSORPROTO.fields_by_name['data_type'].enum_type = _TENSORPROTO_DATATYPE\n",
        "_TENSORPROTO_DATATYPE.containing_type = _TENSORPROTO\n",
        "DESCRIPTOR.message_types_by_name['TensorProtos'] = _TENSORPROTOS\n",
        "DESCRIPTOR.message_types_by_name['TensorProto'] = _TENSORPROTO\n",
        "_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n",
        "\n",
        "TensorProtos = _reflection.GeneratedProtocolMessageType('TensorProtos', (_message.Message,), {\n",
        "  'DESCRIPTOR' : _TENSORPROTOS,\n",
        "  '__module__' : 'tensor_pb2'\n",
        "  # @@protoc_insertion_point(class_scope:TensorProtos)\n",
        "  })\n",
        "_sym_db.RegisterMessage(TensorProtos)\n",
        "\n",
        "TensorProto = _reflection.GeneratedProtocolMessageType('TensorProto', (_message.Message,), {\n",
        "  'DESCRIPTOR' : _TENSORPROTO,\n",
        "  '__module__' : 'tensor_pb2'\n",
        "  # @@protoc_insertion_point(class_scope:TensorProto)\n",
        "  })\n",
        "_sym_db.RegisterMessage(TensorProto)\n",
        "\n",
        "\n",
        "# @@protoc_insertion_point(module_scope)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor_pb2.TensorProto"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhWnJBAmR-Mi"
      },
      "source": [
        "\n",
        "# Copyright 2019 ASLP@NPU.  All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "#\n",
        "# Author: npuichigo@gmail.com (zhangyuchao)\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tensor_to_numpy_array(tensor):\n",
        "    if tensor.data_type == TensorProto.FLOAT:\n",
        "        return np.asarray(\n",
        "            tensor.float_data, dtype=np.float32).reshape(tensor.dims)\n",
        "    elif tensor.data_type == TensorProto.DOUBLE:\n",
        "        return np.asarray(\n",
        "            tensor.double_data, dtype=np.float64).reshape(tensor.dims)\n",
        "    elif tensor.data_type == TensorProto.INT32:\n",
        "        return np.asarray(\n",
        "            tensor.int32_data, dtype=np.int).reshape(tensor.dims)  # pb.INT32=>np.int use int32_data\n",
        "    elif tensor.data_type == TensorProto.INT16:\n",
        "        return np.asarray(\n",
        "            tensor.int32_data, dtype=np.int16).reshape(tensor.dims)  # pb.INT16=>np.int16 use int32_data\n",
        "    elif tensor.data_type == TensorProto.UINT16:\n",
        "        return np.asarray(\n",
        "            tensor.int32_data, dtype=np.uint16).reshape(tensor.dims)  # pb.UINT16=>np.uint16 use int32_data\n",
        "    elif tensor.data_type == TensorProto.INT8:\n",
        "        return np.asarray(\n",
        "            tensor.int32_data, dtype=np.int8).reshape(tensor.dims)  # pb.INT8=>np.int8 use int32_data\n",
        "    elif tensor.data_type == TensorProto.UINT8:\n",
        "        return np.asarray(\n",
        "            tensor.int32_data, dtype=np.uint8).reshape(tensor.dims)  # pb.UINT8=>np.uint8 use int32_data\n",
        "    else:\n",
        "        # TODO: complete the data type: bool, float16, byte, int64, string\n",
        "        raise RuntimeError(\n",
        "            \"Tensor data type not supported yet: \" + str(tensor.data_type))\n",
        "\n",
        "\n",
        "def numpy_array_to_tensor(arr):\n",
        "    tensor = TensorProto()\n",
        "    tensor.dims.extend(arr.shape)\n",
        "    if arr.dtype == np.float32:\n",
        "        tensor.data_type = TensorProto.FLOAT\n",
        "        tensor.float_data.extend(list(arr.flatten().astype(float)))\n",
        "    elif arr.dtype == np.float64:\n",
        "        tensor.data_type = TensorProto.DOUBLE\n",
        "        tensor.double_data.extend(list(arr.flatten().astype(np.float64)))\n",
        "    elif arr.dtype == np.int or arr.dtype == np.int32:\n",
        "        tensor.data_type = TensorProto.INT32\n",
        "        tensor.int32_data.extend(arr.flatten().astype(np.int).tolist())\n",
        "    elif arr.dtype == np.int16:\n",
        "        tensor.data_type = TensorProto.INT16\n",
        "        tensor.int32_data.extend(list(arr.flatten().astype(np.int16)))  # np.int16=>pb.INT16 use int32_data\n",
        "    elif arr.dtype == np.uint16:\n",
        "        tensor.data_type = TensorProto.UINT16\n",
        "        tensor.int32_data.extend(list(arr.flatten().astype(np.uint16)))  # np.uint16=>pb.UNIT16 use int32_data\n",
        "    elif arr.dtype == np.int8:\n",
        "        tensor.data_type = TensorProto.INT8\n",
        "        tensor.int32_data.extend(list(arr.flatten().astype(np.int8)))  # np.int8=>pb.INT8 use int32_data\n",
        "    elif arr.dtype == np.uint8:\n",
        "        tensor.data_type = TensorProto.UINT8\n",
        "        tensor.int32_data.extend(list(arr.flatten().astype(np.uint8)))  # np.uint8=>pb.UNIT8 use int32_data\n",
        "    else:\n",
        "        # TODO: complete the data type: bool, float16, byte, int64, string\n",
        "        raise RuntimeError(\n",
        "            \"Numpy data type not supported yet: \" + str(arr.dtype))\n",
        "    return tensor"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5nKUlcKRogK"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class LmdbDataset(Dataset):\n",
        "    \"\"\"Lmdb dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, lmdb_path):\n",
        "        super(LmdbDataset, self).__init__()\n",
        "        import lmdb\n",
        "        self.env = lmdb.open(lmdb_path, max_readers=1, readonly=True, lock=False,\n",
        "                             readahead=False, meminit=False)\n",
        "        with self.env.begin(write=False) as txn:\n",
        "            self.length = txn.stat()['entries']\n",
        "            self.keys = [key for key, _ in txn.cursor()]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        with self.env.begin(write=False) as txn:\n",
        "            serialized_str = txn.get(self.keys[index])\n",
        "        tensor_protos = TensorProtos()\n",
        "        tensor_protos.ParseFromString(serialized_str)\n",
        "\n",
        "        img = tensor_to_numpy_array(tensor_protos.protos[0])\n",
        "        label = tensor_to_numpy_array(tensor_protos.protos[1])\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqHkPaEW-ax3"
      },
      "source": [
        "# 导入数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP9Dru0S-cbI",
        "outputId": "5bd3998e-ad34-47a7-dc35-0cd7854c38fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "#! /usr/bin/enc python\n",
        "# -*- coding: utf-8 -*-\n",
        "# author: Jarvis Dong\n",
        "# email: cauc1ronman@outlook.com\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "lmdb_path = \"/content/drive/My Drive/Research/Data/Train2\"\n",
        "test_lmdb_path = \"/content/drive/My Drive/Research/Data/Test2\"\n",
        "\n",
        "\n",
        "# Resnet_ecg = resnet34()\n",
        "# Resnet_ecg.to(device)\n",
        "# Resnet_ecg = Explo_batch_net()\n",
        "# Resnet_ecg.to(device)\n",
        "Resnet_ecg = ResNet_ecg(**config)\n",
        "Resnet_ecg.to(device)\n",
        "\n",
        "# optimizer = optim.Adam(Resnet_ecg.parameters(),lr=1e-2,weight_decay=4e-5)\n",
        "# optimizer = optim.Adam(Resnet_ecg.parameters(), lr=1e-2, weight_decay=1e-3)\n",
        "optimizer = optim.SGD(Resnet_ecg.parameters(), lr=1e-3, momentum=0.9, weight_decay=4e-5) \n",
        "\n",
        "# lr decay policy \n",
        "# milestones = [60,120,160]\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True) \n",
        "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones,gamma=0.1) # learning rate decay (cifar100 params)\n",
        "loss_func = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "\n",
        "# warmup with pytorch_warmup pkg \n",
        "# import pytorch_warmup as warmup \n",
        "# warm\n",
        "\n",
        "test_loss = np.zeros([num_epochs,1]) \n",
        "\n",
        "training = LmdbDataset(lmdb_path)\n",
        "Train = DataLoader(training, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "testing = LmdbDataset(test_lmdb_path)\n",
        "Test = DataLoader(testing,batch_size=len(testing),shuffle=True,num_workers=0)\n",
        "\n",
        "training_loss_record = np.zeros([num_epochs,1])\n",
        "testing_loss_record = np.zeros([num_epochs,1]) \n",
        "\n",
        "for batch_idx,batch in enumerate(Train):\n",
        "  input_x,input_y=tuple(t for t in batch)\n",
        "  print(input_x.shape)\n",
        "  print(input_y.shape)\n",
        "  plt.plot(input_x[29])\n",
        "  print(input_y)\n",
        "  break\n",
        "\n",
        "for batch_idx,batch in enumerate(Test):\n",
        "  input_x,input_y=tuple(t for t in batch)\n",
        "  print(input_x.shape)\n",
        "  print(input_y.shape)  \n",
        "\n",
        "print(len(Train.dataset))\n",
        "\n",
        "# print(len(Test.dataset))\n",
        "\n",
        "# input_y -= torch.ones(input_y.shape)  \n",
        "# plt.plot(input_x[50].cpu().numpy(),'b-',label='original signal')\n",
        "\n",
        "# detrending_signal = input_x[50].cpu().numpy()-\\\n",
        "# poly_fit_utils(input_y[50].cpu().numpy(),times,\\\n",
        "#                input_x[50].cpu().numpy())[0]\n",
        "\n",
        "# plt.plot(detrending_signal,'r--',label='detrending signal')\n",
        "# plt.grid()\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "# print(input_y.cpu().numpy())\n",
        "# input_y -= 1\n",
        "# print(\"current order:\", input_y[50])  \n",
        "\n",
        "# plt.plot(input_x[50].cpu().numpy()/np.max(input_x[50].cpu().numpy()),'b-',label='original signal')\n",
        "# plt.show() \n",
        "\n",
        "# plt.plot(input_x[50].cpu()/torch.max(input_x[50].cpu()),'r-',label='original signal')\n",
        "# plt.show()\n",
        "\n",
        "# print(input_x[0:10])\n",
        "# print(input_x[0:10]/torch.max(input_x[0:10].cpu()))\n",
        "\n",
        "# warmup trick \n",
        "# print(\"iter_per_epoch:\",len(Train))\n",
        "# warm = 1 # 10个epoch的warmup \n",
        "# warmup_scheduler = WarmUpLR(optimizer,len(Train)*warm) \n",
        "\n",
        "# Resnet_ecg.to(device)  \n",
        "# Resnet_ecg.load_state_dict(torch.load(\"/content/drive/My Drive/Pytorch/Model_WorkFre/Work_order_predict_without_norm_1Res18_3.pt\"))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 187])\n",
            "torch.Size([64])\n",
            "tensor([2., 4., 0., 4., 2., 2., 4., 0., 0., 2., 2., 0., 4., 0., 1., 2., 4., 4.,\n",
            "        4., 0., 0., 0., 0., 2., 0., 0., 2., 2., 0., 4., 2., 0., 4., 4., 1., 1.,\n",
            "        2., 2., 0., 4., 4., 0., 0., 1., 2., 0., 2., 0., 4., 2., 2., 2., 4., 0.,\n",
            "        4., 4., 2., 0., 0., 1., 2., 4., 0., 0.], dtype=torch.float64)\n",
            "torch.Size([2000, 187])\n",
            "torch.Size([2000])\n",
            "23000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfxOmy78BHdc",
        "outputId": "c865bbe1-ffef-432d-8e2f-514f40a78171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch \n",
        "# 清除GPU内存 \n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(Resnet_ecg)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet_ecg(\n",
            "  (0): Sequential(\n",
            "    (0): Conv1d(1, 128, kernel_size=(31,), stride=(4,), padding=(15,), bias=False)\n",
            "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool1d(kernel_size=15, stride=4, padding=5, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (conv1): Conv1d(128, 128, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
            "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv1d(128, 128, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv1d(128, 128, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
            "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (conv1): Conv1d(128, 128, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv1d(128, 128, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (conv1): Conv1d(128, 256, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
            "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv1d(128, 256, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
            "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (conv1): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (conv1): Conv1d(256, 512, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
            "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv1d(512, 512, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv1d(256, 512, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
            "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (conv1): Conv1d(512, 512, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv1d(512, 512, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (conv1): Conv1d(512, 1024, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
            "        (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv1d(1024, 1024, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv1d(512, 1024, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
            "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (conv1): Conv1d(1024, 1024, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv1d(1024, 1024, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
            "        (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): AdaptiveAvgPool1d(output_size=1)\n",
            "    (1): Flatten()\n",
            "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
            "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKtV6K_4Gj1j"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmN5owuIGmc6",
        "outputId": "558a7bfd-eac1-444b-dca3-e5c12b44f301",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#! /usr/bin/enc python\n",
        "# -*- coding: utf-8 -*-\n",
        "# author: Jarvis Dong\n",
        "# email: cauc1ronman@outlook.com\n",
        "\n",
        "best_acc = 0.0\n",
        "\n",
        "# performance params \n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  # if epoch >= warm:\n",
        "    # scheduler.step(test_loss)\n",
        "\n",
        "  # epoch = 0 \n",
        "  loss_x = []\n",
        "  loss_x2 = []\n",
        "\n",
        "  # train \n",
        "  Resnet_ecg.train()\n",
        "  train_loss = 0 \n",
        "\n",
        "  for batch_idx,batch in enumerate(Train):\n",
        "\n",
        "    # # ---------- Warmup stage ------------ \n",
        "    # if epoch < warm:\n",
        "    #   warmup_scheduler.step()\n",
        "    \n",
        "    # if epoch < warm and batch_idx == 0: \n",
        "    #   print(\"ε=(´ο｀*)) Warmup_stage... \") \n",
        "    # # ---------------------------------------\n",
        "\n",
        "    input_x,input_y = tuple(t.to(device) for t in batch)\n",
        "    max = torch.max(input_x.cpu())\n",
        "    input_x /= max\n",
        "    # input_x = torch.reshape(input_x,(input_x.shape[0],8,256))\n",
        "    input_x = torch.unsqueeze(input_x,1)\n",
        "    # input_y -= 1 \n",
        "    # input_x = input_x.type(torch.FloatTensor)\n",
        "    # input_y = input_y.type(torch.FloatTensor)\n",
        "    pred = Resnet_ecg(input_x.to(device))\n",
        "    loss = loss_func(pred,input_y.type(torch.LongTensor).to(device))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # step += 1 \n",
        "    loss_x.append(loss.item()) \n",
        "    train_loss += loss.item()\n",
        "\n",
        "  training_loss_record[epoch] = train_loss/len(Train)\n",
        "  print(\"epoch:{}, current training loss:{}\".format(epoch,training_loss_record[epoch]))\n",
        "\n",
        "  # releasing unnecessary memory in GPU \n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache() \n",
        "\n",
        "  # ------------------ val ---------------------------------------- \n",
        "  # if epoch % test_every_epoch == 0:\n",
        "    \n",
        "  Resnet_ecg.eval()\n",
        "\n",
        "  # test \n",
        "  test_loss = 0 \n",
        "  correct = 0 \n",
        "  precision,recall,f1,accuracy = [],[],[],[] \n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_idx,batch in enumerate(Test):\n",
        "      input_x,input_y=tuple(t.to(device) for t in batch)\n",
        "      max = torch.max(input_x.cpu())\n",
        "      input_x /= max\n",
        "      input_x = input_x.unsqueeze(1)\n",
        "      # input_x = torch.reshape(input_x,(input_x.shape[0],8,256))\n",
        "      # input_x = input_x.type(torch.FloatTensor)\n",
        "      # input_y = input_y.type(torch.FloatTensor) \n",
        "      # input_y -= 1 \n",
        "      pred = Resnet_ecg(input_x.to(device))\n",
        "      loss = loss_func(pred,input_y.type(torch.LongTensor).to(device))\n",
        "      test_loss += loss.item() \n",
        "      pred_label = pred.data.max(1)[1] # get the index of the max log-probability \n",
        "      correct += pred_label.cpu().eq(input_y.cpu()).sum() \n",
        "\n",
        "      # calculate P/R/F1/A metrics for batch\n",
        "      for acc, metric in zip((precision, recall, f1, accuracy), \n",
        "            (precision_score, recall_score, f1_score, accuracy_score)):\n",
        "        acc.append(\n",
        "            calculate_metric(metric, input_y.cpu(), pred_label.cpu())\n",
        "        )\n",
        "\n",
        "  test_loss = test_loss / len(Test)\n",
        "  \n",
        "  testing_loss_record[epoch] = test_loss\n",
        "  accu = 100.*correct/len(Test.dataset)\n",
        "\n",
        "  print_scores(precision, recall, f1, accuracy, len(Test))\n",
        "  print(\"epoch:\",epoch,\"---current_test_loss:\",test_loss,\"---accuracy:\",accu.numpy(),\"%\")\n",
        "\n",
        "  # model saving \n",
        "  if (epoch+1) % save_every_epoch == 0: \n",
        "    model_dir = '/content/drive/My Drive/Research/save_models/'\n",
        "    model_name = 'ECG_predict_0.pt'\n",
        "    torch.save(Resnet_ecg.state_dict(), model_dir+model_name)\n",
        "    print(\"Saving complete!\") \n",
        "  \n",
        "  # save the best \n",
        "  if accu > best_acc: \n",
        "    best_acc = accu \n",
        "    model_dir = '/content/drive/My Drive/Research/save_models/'\n",
        "    model_name = 'ECG_predict_best_0.pt'\n",
        "    torch.save(Resnet_ecg.state_dict(), model_dir+model_name)\n",
        "    print(\"Saving best model complete!\") \n",
        "  \n",
        "  scheduler.step(test_loss) \n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"End...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0, current training loss:[0.38336387]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t     precision: 0.2500\n",
            "\t        recall: 0.2384\n",
            "\t            F1: 0.2440\n",
            "\t      accuracy: 0.9535\n",
            "epoch: 0 ---current_test_loss: 0.12290399521589279 ---accuracy: 95.35 %\n",
            "Saving best model complete!\n",
            "epoch:1, current training loss:[0.23157615]\n",
            "\t     precision: 0.2500\n",
            "\t        recall: 0.2377\n",
            "\t            F1: 0.2437\n",
            "\t      accuracy: 0.9510\n",
            "epoch: 1 ---current_test_loss: 0.12590332329273224 ---accuracy: 95.1 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}